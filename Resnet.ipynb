{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzGLDywe7mXf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4-4-5sN7qoc",
        "outputId": "12f44502-e585-4acd-c0be-9f801ea4eb6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "h1KLyN3L_5t9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess.py\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/dataset\"  # Update with your dataset path\n",
        "IMG_SIZE = 224\n",
        "SEQUENCE_LENGTH = 30\n",
        "\n",
        "def extract_frames(video_path, sequence_length=SEQUENCE_LENGTH):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_interval = max(total_frames // sequence_length, 1)\n",
        "\n",
        "    for i in range(sequence_length):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_interval)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
        "        frames.append(frame)\n",
        "\n",
        "    while len(frames) < sequence_length:\n",
        "        frames.append(frames[-1])\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def load_data():\n",
        "    X, y = [], []\n",
        "\n",
        "    for label, subdir in enumerate([\"violence\", \"non_violence\"]):\n",
        "        subdir_path = os.path.join(DATASET_DIR, subdir)\n",
        "        for video_file in os.listdir(subdir_path):\n",
        "            video_path = os.path.join(subdir_path, video_file)\n",
        "            frames = extract_frames(video_path)\n",
        "            X.append(frames)\n",
        "            y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "# Load and preprocess the data\n",
        "X, y = load_data()\n",
        "X = X / 255.0  # Normalize frames\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save preprocessed data\n",
        "np.save('/content/X_train.npy', X_train)\n",
        "np.save('/content/X_test.npy', X_test)\n",
        "np.save('/content/y_train.npy', y_train)\n",
        "np.save('/content/y_test.npy', y_test)\n",
        "\n",
        "print(\"Data preprocessing completed. Data saved as .npy files.\")\n"
      ],
      "metadata": {
        "id": "zz-qdn4V__fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_extraction.py\n",
        "\n",
        "IMG_SIZE = 224\n",
        "SEQUENCE_LENGTH = 30\n",
        "\n",
        "# Load the pre-trained ResNet50 model for feature extraction\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "model = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
        "\n",
        "def extract_features(X):\n",
        "    num_samples = X.shape[0]\n",
        "    features = np.zeros((num_samples, SEQUENCE_LENGTH, model.output_shape[-1]))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        for j in range(SEQUENCE_LENGTH):\n",
        "            features[i, j, :] = model.predict(np.expand_dims(X[i, j], axis=0))[0]\n",
        "\n",
        "    return features\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train = np.load('/content/X_train.npy')\n",
        "X_test = np.load('/content/X_test.npy')\n",
        "\n",
        "# Extract features\n",
        "X_train_features = extract_features(X_train)\n",
        "X_test_features = extract_features(X_test)\n",
        "\n",
        "# Save extracted features\n",
        "np.save('/content/X_train_features.npy', X_train_features)\n",
        "np.save('/content/X_test_features.npy', X_test_features)\n",
        "\n",
        "print(\"Feature extraction completed. Features saved as .npy files.\")\n"
      ],
      "metadata": {
        "id": "6oE6F72PONHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = tf.keras.Sequential([\n",
        "        LSTM(64, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.5),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define model input shape\n",
        "input_shape = (30, 2048)  # Example input shape\n",
        "model = build_model(input_shape)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "7zwFbkLmOT_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "\n",
        "# Load the extracted features and labels\n",
        "X_train_features = np.load('/content/X_train_features.npy')\n",
        "X_test_features = np.load('/content/X_test_features.npy')\n",
        "y_train = np.load('/content/y_train.npy')\n",
        "y_test = np.load('/content/y_test.npy')\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X_train_features.shape[1], X_train_features.shape[2])\n",
        "model = build_model(input_shape)\n",
        "\n",
        "# Define model checkpoint\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('/content/violence_detection_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_features, y_train, epochs=10, batch_size=16, validation_data=(X_test_features, y_test), callbacks=[checkpoint])\n",
        "\n",
        "print(\"Training completed.\")\n"
      ],
      "metadata": {
        "id": "wDKo6z0IOYYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate.py\n",
        "\n",
        "# Load the test features and labels\n",
        "X_test_features = np.load('/content/X_test_features.npy')\n",
        "y_test = np.load('/content/y_test.npy')\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/violence_detection_model.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_features, y_test, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test_features)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate accuracy manually\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "LB3uAxLtOdd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}